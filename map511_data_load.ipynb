{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a35551f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "from gensim.models import Word2Vec\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "from sklearn.manifold import TSNE\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c283a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-1.13.3-py3-none-any.whl (287 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from datasets) (1.20.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from datasets) (1.2.4)\n",
      "Collecting huggingface-hub<0.1.0,>=0.0.19\n",
      "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "Collecting tqdm>=4.62.1\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from datasets) (20.9)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp38-cp38-win_amd64.whl (635 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (5.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.5.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cheikh ahmed\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: async-timeout, tqdm, fsspec, dill, aiohttp, xxhash, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.59.0\n",
      "    Uninstalling tqdm-4.59.0:\n",
      "      Successfully uninstalled tqdm-4.59.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.9.0\n",
      "    Uninstalling fsspec-0.9.0:\n",
      "      Successfully uninstalled fsspec-0.9.0\n",
      "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.13.3 dill-0.3.4 fsspec-2021.10.1 huggingface-hub-0.0.19 multiprocess-0.70.12.2 tqdm-4.62.3 xxhash-2.0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaa33d428944cd1862bd1ad037a16be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3562aab74843d49b6214105f6b4252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cnn_dailymail/3.0.0 (download: 558.32 MiB, generated: 1.28 GiB, post-processed: Unknown size, total: 1.82 GiB) to C:\\Users\\cheikh ahmed\\.cache\\huggingface\\datasets\\cnn_dailymail\\3.0.0\\3.0.0\\3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2c91537b9b42efb3565fad63e68220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4c315aa803456dab801b27c224e931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f99ee0fb3247d090c36428a846965b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8af6a02ddf4bd4bae4bd656ee290f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/572k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad2221e38c44e97a309bfef4affbf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cc7b50cdef4f1ab2205b04ca489d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/661k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b10bce5f584ac28360bf4cf3f47378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cnn_dailymail downloaded and prepared to C:\\Users\\cheikh ahmed\\.cache\\huggingface\\datasets\\cnn_dailymail\\3.0.0\\3.0.0\\3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffee0946da854084b3391e730d156b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "   'cnn_dailymail', '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8728b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e430cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_article = train['article']\n",
    "train_highlights = train['highlights']\n",
    "train_id = train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e93c07ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_highlights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "107f4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split(' ') for row in train_highlights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1646d32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 23:51:28: collecting all words and their counts\n",
      "INFO - 23:51:28: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 23:51:28: PROGRESS: at sentence #10000, processed 429172 words, keeping 55275 word types\n",
      "INFO - 23:51:28: PROGRESS: at sentence #20000, processed 859008 words, keeping 83644 word types\n",
      "INFO - 23:51:28: PROGRESS: at sentence #30000, processed 1287804 words, keeping 106257 word types\n",
      "INFO - 23:51:28: PROGRESS: at sentence #40000, processed 1717121 words, keeping 125100 word types\n",
      "INFO - 23:51:28: PROGRESS: at sentence #50000, processed 2146340 words, keeping 141818 word types\n",
      "INFO - 23:51:28: PROGRESS: at sentence #60000, processed 2576060 words, keeping 157303 word types\n",
      "INFO - 23:51:28: PROGRESS: at sentence #70000, processed 3005320 words, keeping 171338 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #80000, processed 3435560 words, keeping 184401 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #90000, processed 3864644 words, keeping 196600 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #100000, processed 4378068 words, keeping 222235 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #110000, processed 4892511 words, keeping 244118 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #120000, processed 5406641 words, keeping 263848 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #130000, processed 5921784 words, keeping 282531 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #140000, processed 6440313 words, keeping 300216 word types\n",
      "INFO - 23:51:29: PROGRESS: at sentence #150000, processed 6952360 words, keeping 316698 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #160000, processed 7466650 words, keeping 332289 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #170000, processed 7977893 words, keeping 347347 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #180000, processed 8489440 words, keeping 362064 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #190000, processed 8999977 words, keeping 375727 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #200000, processed 9511206 words, keeping 389265 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #210000, processed 10024957 words, keeping 402370 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #220000, processed 10542992 words, keeping 415035 word types\n",
      "INFO - 23:51:30: PROGRESS: at sentence #230000, processed 11055355 words, keeping 427467 word types\n",
      "INFO - 23:51:31: PROGRESS: at sentence #240000, processed 11567756 words, keeping 439890 word types\n",
      "INFO - 23:51:31: PROGRESS: at sentence #250000, processed 12078289 words, keeping 451718 word types\n",
      "INFO - 23:51:31: PROGRESS: at sentence #260000, processed 12590087 words, keeping 463363 word types\n",
      "INFO - 23:51:31: PROGRESS: at sentence #270000, processed 13107387 words, keeping 474920 word types\n",
      "INFO - 23:51:31: PROGRESS: at sentence #280000, processed 13622606 words, keeping 486316 word types\n",
      "INFO - 23:51:31: collected 494275 word types from a corpus of 13988232 raw words and 287113 sentences\n",
      "INFO - 23:51:31: Creating a fresh vocabulary\n",
      "INFO - 23:51:34: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 494275 unique words (100.0%% of original 494275, drops 0)', 'datetime': '2021-10-18T23:51:34.015258', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 23:51:34: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 13988232 word corpus (100.0%% of original 13988232, drops 0)', 'datetime': '2021-10-18T23:51:34.016253', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 23:51:37: deleting the raw counts dictionary of 494275 items\n",
      "INFO - 23:51:37: sample=0.001 downsamples 34 most-common words\n",
      "INFO - 23:51:37: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 11669118.219085773 word corpus (83.4%% of prior 13988232)', 'datetime': '2021-10-18T23:51:37.107991', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 23:51:41: estimated required memory for 494275 words and 50 dimensions: 444847500 bytes\n",
      "INFO - 23:51:41: resetting layer weights\n",
      "INFO - 23:51:41: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-10-18T23:51:41.824386', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "INFO - 23:51:41: Word2Vec lifecycle event {'msg': 'training model with 3 workers on 494275 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=3', 'datetime': '2021-10-18T23:51:41.825383', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 23:51:42: EPOCH 1 - PROGRESS: at 4.37% examples, 448626 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:43: EPOCH 1 - PROGRESS: at 8.91% examples, 456401 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:44: EPOCH 1 - PROGRESS: at 13.44% examples, 459264 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:45: EPOCH 1 - PROGRESS: at 18.06% examples, 462903 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:46: EPOCH 1 - PROGRESS: at 22.75% examples, 467407 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:47: EPOCH 1 - PROGRESS: at 27.27% examples, 467565 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:48: EPOCH 1 - PROGRESS: at 31.81% examples, 468669 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:49: EPOCH 1 - PROGRESS: at 35.64% examples, 468718 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:50: EPOCH 1 - PROGRESS: at 39.64% examples, 468653 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:51: EPOCH 1 - PROGRESS: at 43.62% examples, 469745 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:52: EPOCH 1 - PROGRESS: at 47.25% examples, 466684 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:53: EPOCH 1 - PROGRESS: at 50.83% examples, 464377 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:55: EPOCH 1 - PROGRESS: at 54.40% examples, 461311 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:56: EPOCH 1 - PROGRESS: at 58.25% examples, 461118 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:57: EPOCH 1 - PROGRESS: at 62.06% examples, 460473 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:58: EPOCH 1 - PROGRESS: at 65.94% examples, 460773 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:51:59: EPOCH 1 - PROGRESS: at 69.89% examples, 461541 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:00: EPOCH 1 - PROGRESS: at 73.72% examples, 461571 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:01: EPOCH 1 - PROGRESS: at 77.56% examples, 462085 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:02: EPOCH 1 - PROGRESS: at 81.28% examples, 461122 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:03: EPOCH 1 - PROGRESS: at 85.30% examples, 462148 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:04: EPOCH 1 - PROGRESS: at 89.22% examples, 462947 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:05: EPOCH 1 - PROGRESS: at 93.07% examples, 463354 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:06: EPOCH 1 - PROGRESS: at 96.92% examples, 463594 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:52:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:52:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:52:06: EPOCH - 1 : training on 13988232 raw words (11669048 effective words) took 25.1s, 463985 effective words/s\n",
      "INFO - 23:52:07: EPOCH 2 - PROGRESS: at 4.53% examples, 468296 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:09: EPOCH 2 - PROGRESS: at 9.15% examples, 469040 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:52:10: EPOCH 2 - PROGRESS: at 13.68% examples, 469189 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:11: EPOCH 2 - PROGRESS: at 18.14% examples, 465753 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:12: EPOCH 2 - PROGRESS: at 22.50% examples, 459136 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:13: EPOCH 2 - PROGRESS: at 26.95% examples, 458461 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 23:52:14: EPOCH 2 - PROGRESS: at 31.54% examples, 458671 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:15: EPOCH 2 - PROGRESS: at 35.38% examples, 458594 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:16: EPOCH 2 - PROGRESS: at 39.24% examples, 458708 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:17: EPOCH 2 - PROGRESS: at 43.08% examples, 459063 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:18: EPOCH 2 - PROGRESS: at 46.72% examples, 457814 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:19: EPOCH 2 - PROGRESS: at 50.35% examples, 456004 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:20: EPOCH 2 - PROGRESS: at 54.00% examples, 454605 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:21: EPOCH 2 - PROGRESS: at 57.72% examples, 454699 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:22: EPOCH 2 - PROGRESS: at 61.52% examples, 455178 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:23: EPOCH 2 - PROGRESS: at 65.33% examples, 455404 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:24: EPOCH 2 - PROGRESS: at 69.07% examples, 454588 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:25: EPOCH 2 - PROGRESS: at 72.92% examples, 455256 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:26: EPOCH 2 - PROGRESS: at 76.75% examples, 455519 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:27: EPOCH 2 - PROGRESS: at 80.67% examples, 455974 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:28: EPOCH 2 - PROGRESS: at 84.34% examples, 455426 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:29: EPOCH 2 - PROGRESS: at 88.41% examples, 456688 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:30: EPOCH 2 - PROGRESS: at 92.33% examples, 457282 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:31: EPOCH 2 - PROGRESS: at 96.24% examples, 458155 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:52:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:52:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:52:32: EPOCH - 2 : training on 13988232 raw words (11670505 effective words) took 25.4s, 458798 effective words/s\n",
      "INFO - 23:52:33: EPOCH 3 - PROGRESS: at 4.29% examples, 442897 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:34: EPOCH 3 - PROGRESS: at 8.75% examples, 447308 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:35: EPOCH 3 - PROGRESS: at 12.87% examples, 440087 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:36: EPOCH 3 - PROGRESS: at 17.25% examples, 442526 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:37: EPOCH 3 - PROGRESS: at 21.69% examples, 446171 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:38: EPOCH 3 - PROGRESS: at 26.30% examples, 448830 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:39: EPOCH 3 - PROGRESS: at 30.92% examples, 452565 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:40: EPOCH 3 - PROGRESS: at 34.85% examples, 454856 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:41: EPOCH 3 - PROGRESS: at 38.63% examples, 454849 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:42: EPOCH 3 - PROGRESS: at 42.47% examples, 455434 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:43: EPOCH 3 - PROGRESS: at 46.32% examples, 456204 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:44: EPOCH 3 - PROGRESS: at 50.08% examples, 456164 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:45: EPOCH 3 - PROGRESS: at 53.93% examples, 456580 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:46: EPOCH 3 - PROGRESS: at 57.78% examples, 457232 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:47: EPOCH 3 - PROGRESS: at 61.59% examples, 456829 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:48: EPOCH 3 - PROGRESS: at 65.47% examples, 457565 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:49: EPOCH 3 - PROGRESS: at 69.27% examples, 457302 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:50: EPOCH 3 - PROGRESS: at 73.13% examples, 457852 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:51: EPOCH 3 - PROGRESS: at 76.88% examples, 457787 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:52: EPOCH 3 - PROGRESS: at 80.67% examples, 457676 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:53: EPOCH 3 - PROGRESS: at 84.48% examples, 457879 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:54: EPOCH 3 - PROGRESS: at 88.27% examples, 457947 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:55: EPOCH 3 - PROGRESS: at 92.07% examples, 458186 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:52:56: EPOCH 3 - PROGRESS: at 95.69% examples, 457595 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:57: EPOCH 3 - PROGRESS: at 99.54% examples, 458152 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:52:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:52:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:52:57: EPOCH - 3 : training on 13988232 raw words (11668033 effective words) took 25.5s, 457924 effective words/s\n",
      "INFO - 23:52:58: EPOCH 4 - PROGRESS: at 4.45% examples, 460595 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:52:59: EPOCH 4 - PROGRESS: at 8.75% examples, 444221 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:00: EPOCH 4 - PROGRESS: at 13.11% examples, 443602 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:01: EPOCH 4 - PROGRESS: at 17.08% examples, 435308 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:03: EPOCH 4 - PROGRESS: at 21.21% examples, 432567 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:04: EPOCH 4 - PROGRESS: at 25.82% examples, 438202 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:53:05: EPOCH 4 - PROGRESS: at 30.43% examples, 443022 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:53:06: EPOCH 4 - PROGRESS: at 34.44% examples, 446776 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:53:07: EPOCH 4 - PROGRESS: at 38.29% examples, 448826 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:08: EPOCH 4 - PROGRESS: at 42.14% examples, 450523 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:09: EPOCH 4 - PROGRESS: at 45.92% examples, 451323 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:53:10: EPOCH 4 - PROGRESS: at 49.74% examples, 452953 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:11: EPOCH 4 - PROGRESS: at 53.59% examples, 454100 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:12: EPOCH 4 - PROGRESS: at 57.45% examples, 455149 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:13: EPOCH 4 - PROGRESS: at 61.31% examples, 455764 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:14: EPOCH 4 - PROGRESS: at 65.20% examples, 456533 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:15: EPOCH 4 - PROGRESS: at 69.14% examples, 457240 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:16: EPOCH 4 - PROGRESS: at 73.06% examples, 458221 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:17: EPOCH 4 - PROGRESS: at 76.88% examples, 458897 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:18: EPOCH 4 - PROGRESS: at 80.74% examples, 459479 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:19: EPOCH 4 - PROGRESS: at 84.61% examples, 460014 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:20: EPOCH 4 - PROGRESS: at 88.21% examples, 458924 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:21: EPOCH 4 - PROGRESS: at 91.60% examples, 456994 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:22: EPOCH 4 - PROGRESS: at 94.82% examples, 453148 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:23: EPOCH 4 - PROGRESS: at 98.12% examples, 450936 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:23: EPOCH - 4 : training on 13988232 raw words (11668752 effective words) took 25.9s, 449861 effective words/s\n",
      "INFO - 23:53:24: EPOCH 5 - PROGRESS: at 4.05% examples, 410738 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:25: EPOCH 5 - PROGRESS: at 8.26% examples, 420714 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:53:26: EPOCH 5 - PROGRESS: at 12.39% examples, 419197 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:27: EPOCH 5 - PROGRESS: at 16.51% examples, 419644 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:28: EPOCH 5 - PROGRESS: at 20.48% examples, 417209 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:29: EPOCH 5 - PROGRESS: at 24.37% examples, 413924 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:30: EPOCH 5 - PROGRESS: at 28.08% examples, 408945 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:32: EPOCH 5 - PROGRESS: at 31.67% examples, 404067 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:33: EPOCH 5 - PROGRESS: at 34.71% examples, 399970 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:34: EPOCH 5 - PROGRESS: at 37.67% examples, 396407 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:35: EPOCH 5 - PROGRESS: at 40.73% examples, 393806 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:36: EPOCH 5 - PROGRESS: at 43.75% examples, 391941 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:37: EPOCH 5 - PROGRESS: at 46.92% examples, 391596 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:38: EPOCH 5 - PROGRESS: at 49.95% examples, 390265 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:39: EPOCH 5 - PROGRESS: at 53.25% examples, 390744 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:40: EPOCH 5 - PROGRESS: at 56.77% examples, 392820 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:41: EPOCH 5 - PROGRESS: at 60.16% examples, 393729 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 23:53:42: EPOCH 5 - PROGRESS: at 63.71% examples, 395295 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:43: EPOCH 5 - PROGRESS: at 67.17% examples, 396176 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:44: EPOCH 5 - PROGRESS: at 70.64% examples, 397490 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:45: EPOCH 5 - PROGRESS: at 73.98% examples, 398262 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:46: EPOCH 5 - PROGRESS: at 77.43% examples, 398798 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:47: EPOCH 5 - PROGRESS: at 80.87% examples, 399242 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:48: EPOCH 5 - PROGRESS: at 84.28% examples, 399591 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:49: EPOCH 5 - PROGRESS: at 87.73% examples, 400044 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:50: EPOCH 5 - PROGRESS: at 91.13% examples, 400542 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:51: EPOCH 5 - PROGRESS: at 94.42% examples, 400567 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:52: EPOCH 5 - PROGRESS: at 97.78% examples, 400762 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 23:53:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 23:53:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 23:53:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 23:53:52: EPOCH - 5 : training on 13988232 raw words (11669640 effective words) took 29.1s, 401475 effective words/s\n",
      "INFO - 23:53:52: Word2Vec lifecycle event {'msg': 'training on 69941160 raw words (58345978 effective words) took 131.1s, 445016 effective words/s', 'datetime': '2021-10-18T23:53:52.935915', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 23:53:52: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=494275, vector_size=50, alpha=0.025)', 'datetime': '2021-10-18T23:53:52.935915', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sent, min_count=1,vector_size= 50,workers=3, window =3, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "baf63179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:07:26: Word2Vec lifecycle event {'fname_or_handle': 'w2v_tmodel', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-10-19T00:07:26.551241', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "INFO - 00:07:26: storing np array 'vectors' to w2v_tmodel.wv.vectors.npy\n",
      "INFO - 00:07:26: storing np array 'syn1neg' to w2v_tmodel.syn1neg.npy\n",
      "INFO - 00:07:27: not storing attribute cum_table\n",
      "INFO - 00:07:27: saved w2v_tmodel\n"
     ]
    }
   ],
   "source": [
    "model.save('w2v_tmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd3ed656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74350166"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('Arab','war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63620c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fail', 0.8516114354133606),\n",
       " ('pursue', 0.8511229753494263),\n",
       " ('accept', 0.846449077129364),\n",
       " ('give', 0.8458802103996277),\n",
       " ('refuse', 0.8452743887901306),\n",
       " ('register', 0.8431159257888794),\n",
       " ('ask', 0.8343332409858704),\n",
       " ('restrict', 0.8324018120765686),\n",
       " ('adopt', 0.8275024890899658),\n",
       " ('reconsider', 0.8274831175804138)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('seek')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "21f56274",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.wv['man'] + model.wv['war']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "958a709d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('serviceman', 0.9044477939605713),\n",
       " ('solider', 0.8969548344612122),\n",
       " ('demonstrator', 0.8786395788192749)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[a], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7b9324b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = 'hot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0f457941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 4.6250557e-06),\n",
       " ('&', 4.443253e-06),\n",
       " ('like', 4.39627e-06),\n",
       " ('include', 4.3909827e-06),\n",
       " ('called', 4.317962e-06)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_output_word(sen , topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31497a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
